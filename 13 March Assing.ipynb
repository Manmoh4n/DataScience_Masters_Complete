{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980ecdb3",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049c79b3",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical test used to compare the means of two or more groups. However, ANOVA requires certain assumptions to be met in order for the results to be valid. These assumptions are:\n",
    "\n",
    "Independence: The observations within each group must be independent of each other.\n",
    "\n",
    "Normality: The data within each group must be normally distributed.\n",
    "\n",
    "Homogeneity of variance: The variance within each group must be approximately equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a09f5",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958385df",
   "metadata": {},
   "source": [
    "- One-way ANOVA: This type of ANOVA is used when there is only one factor that affects the response variable. The factor can have two or more levels, and the goal is to compare the means of the groups defined by these levels. One-way ANOVA is commonly used in experimental studies where the researcher is interested in testing the effect of a single independent variable on a dependent variable.\n",
    "\n",
    "- Two-way ANOVA: This type of ANOVA is used when there are two factors that affect the response variable. The two factors can be either independent or related, and the goal is to assess the main effects of each factor as well as any interactions between them. Two-way ANOVA is commonly used in experimental studies where the researcher is interested in testing the effects of two independent variables on a dependent variable.\n",
    "\n",
    "- Three-way ANOVA: This type of ANOVA is used when there are three factors that affect the response variable. The three factors can be either independent or related, and the goal is to assess the main effects of each factor as well as any interactions between them. Three-way ANOVA is less commonly used compared to one-way or two-way ANOVA, but it can be useful in experimental studies where the researcher is interested in testing the effects of three independent variables on a dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b19d2a",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c75f6f",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of breaking down the total variance of a response variable into its component parts based on the sources of variation in the data. The total variance is divided into two main components: variance between groups and variance within groups.\n",
    "\n",
    "The variance between groups represents the variation in the response variable that can be attributed to differences between the groups being compared, while the variance within groups represents the variation in the response variable that cannot be explained by the group membership alone.\n",
    "\n",
    "Partitioning the variance in ANOVA is important because it allows us to determine if the differences between groups are statistically significant or simply due to chance. By comparing the variance between groups to the variance within groups, we can determine if the observed differences in means between groups are large enough to be considered statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4740a97c",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098f4d0",
   "metadata": {},
   "source": [
    "Fit a one-way ANOVA model using the ols function from statsmodels.formula.api. We then use the sm.stats.anova_lm function to calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR), with the typ=1 argument specifying that we want to use the Type I sum of squares method. Finally, we print out the values of SST, SSE, and SSR.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac675abf",
   "metadata": {},
   "source": [
    " # Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed2f65e",
   "metadata": {},
   "source": [
    "Fit a two-way ANOVA model using the ols function from statsmodels.formula.api. The factor1 and factor2 terms represent the main effects of the two independent variables, while the factor1:factor2 term represents the interaction effect. We then use the params attribute of the fitted model object to extract the coefficients (or parameter estimates) for the main effects and interaction effect, and store them in the main_effects and interaction_effect variables, respectively. Finally, we print out the values of the main effects and interaction effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32edc59",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de36f0f",
   "metadata": {},
   "source": [
    "\n",
    "If you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, you can conclude that there is a statistically significant difference between the groups.\n",
    "\n",
    "The F-statistic measures the ratio of the variance between groups to the variance within groups. A large F-statistic suggests that the variation between groups is much larger than the variation within groups, which indicates that there may be a significant difference between at least one of the groups.\n",
    "\n",
    "The p-value is the probability of obtaining an F-statistic as extreme as the one observed, assuming that there is no difference between the groups. In this case, a p-value of 0.02 indicates that there is only a 2% chance of obtaining an F-statistic as extreme as 5.23 if there is no difference between the groups. This provides strong evidence against the null hypothesis of no difference between the groups.\n",
    "\n",
    "Therefore, you can conclude that there is a statistically significant difference between at least one pair of the groups. However, you cannot determine which specific pairs of groups differ from each other based solely on the ANOVA results. To identify which pairs of groups differ significantly, you would need to perform post-hoc tests (such as Tukey's HSD test or the Bonferroni correction) or examine the pairwise comparisons of means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f25245",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4741d872",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, missing data can be handled using different methods, each with its own advantages and potential consequences. Here are some common methods for handling missing data in a repeated measures ANOVA:\n",
    "\n",
    "- Pairwise deletion: This method involves excluding any cases with missing data on any variable in the analysis. This results in a reduction of sample size and potentially biased estimates if the data are not missing completely at random (MCAR). Pairwise deletion can be problematic if the missingness is related to the outcome variable or other covariates, as it may lead to biased estimates of the parameters.\n",
    "\n",
    "- Listwise deletion: This method involves excluding any cases with missing data on any variable in the analysis, resulting in a complete case analysis. This is similar to pairwise deletion, but with a more stringent criterion for inclusion in the analysis. Listwise deletion can result in a reduction of sample size and potentially biased estimates if the data are not MCAR.\n",
    "\n",
    "- Imputation: Imputation involves filling in missing data with estimated values. This can be done using various methods, such as mean imputation, regression imputation, or multiple imputation. Imputation methods can increase statistical power by retaining the maximum number of cases for analysis, but the validity of the results depends on the accuracy of the imputation method used. Imputation can also lead to biased estimates if the imputation model is misspecified or if the imputed values are based on unreliable assumptions.\n",
    "\n",
    "- Maximum likelihood estimation: This method involves estimating the parameters of the repeated measures ANOVA model using all available data, including data from cases with missing values. Maximum likelihood estimation is robust to missing data, under the assumption that the data are missing at random (MAR). This approach can provide unbiased estimates of the model parameters and standard errors, but it may be sensitive to the distributional assumptions of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77b39d",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02306067",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after ANOVA to determine which specific pairs of groups differ significantly from each other, after a significant main effect has been found. Here are some common post-hoc tests used after ANOVA and when they might be used:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) test: This test is commonly used when there are multiple comparisons to be made among groups. Tukey's HSD test is considered conservative, and it controls for the family-wise error rate. This test is appropriate when the assumption of equal variances is met.\n",
    "\n",
    "Bonferroni correction: This test is used when there are multiple comparisons to be made among groups and is more conservative than Tukey's HSD test. The Bonferroni correction adjusts the p-values by dividing the desired alpha level by the number of pairwise comparisons being made. This test is appropriate when the assumption of equal variances is met.\n",
    "\n",
    "Scheffe's method: This test is used when there are unequal variances among the groups. Scheffe's method is more conservative than Tukey's HSD test and Bonferroni correction, and it controls for the family-wise error rate. Scheffe's method is the most robust of all the post-hoc tests, but it is also the most conservative.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is when you are comparing the means of three or more groups using ANOVA, and you find a significant main effect. In this case, you would need to conduct a post-hoc test to determine which specific pairs of groups differ significantly from each other. For instance, in a study examining the effect of different study strategies (group A, group B, and group C) on exam scores, if ANOVA finds a significant main effect of study strategy, a post-hoc test can be conducted to determine if the mean exam score of one group is significantly different from the other groups.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51590a",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb4bac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic:  40.14191071007307\n",
      "p-value:  1.3952345973848938e-14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# create sample data\n",
    "diet_A = np.array([3, 4, 2, 5, 6, 4, 3, 5, 4, 3, 2, 4, 5, 3, 4, 2, 4, 3, 4, 5, 6, 4, 5, 4, 6, 5, 4, 3, 5, 4, 2, 3, 5, 6, 5, 4, 5, 6, 5, 4, 6, 7, 5, 4, 3, 4, 5, 3, 4])\n",
    "diet_B = np.array([2, 3, 4, 1, 3, 2, 3, 4, 1, 2, 3, 2, 4, 2, 1, 3, 2, 4, 1, 2, 3, 4, 1, 3, 2, 4, 1, 2, 3, 2, 1, 3, 2, 4, 1, 2, 3, 2, 4, 1, 3, 2, 4, 1, 3, 2, 4, 1, 2, 3])\n",
    "diet_C = np.array([1, 3, 2, 4, 2, 3, 1, 4, 3, 2, 4, 3, 2, 1, 3, 4, 2, 3, 1, 2, 3, 4, 1, 3, 2, 4, 2, 3, 1, 4, 2, 3, 1, 4, 2, 3, 1, 4, 2, 3, 1, 4, 2, 3, 1, 4, 3, 2])\n",
    "\n",
    "# conduct one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# print results\n",
    "print(\"F-statistic: \", f_statistic)\n",
    "print(\"p-value: \", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9fe28",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dea352",
   "metadata": {},
   "source": [
    "In this example, we assume that the data is stored in a CSV file called data.csv, which has columns for Program, Experience, and Time. We read the data into a pandas DataFrame and then use the ols() function from the statsmodels.formula.api module to specify a linear model with the main effects of Program and Experience, as well as their interaction effect. We then fit the model using the fit() method and obtain the ANOVA table using the anova_lm() function from the statsmodels.stats module.\n",
    "\n",
    "The ANOVA table contains several statistics, including the F-statistics and p-values for the main effects of Program and Experience, as well as their interaction effect. The F-statistic measures the ratio of the variance between groups to the variance within groups, and the p-value measures the probability of observing an F-statistic as extreme as the one observed, assuming that the null hypothesis is true. A p-value less than 0.05 indicates that the effect is statistically significant, while a p-value greater than 0.05 indicates that the effect is not statistically significant.\n",
    "\n",
    "To interpret the results of our example code snippet, we would look at the p-values for the main effects of Program and Experience, as well as their interaction effect. If any of these p-values are less than 0.05, we can conclude that there is a statistically significant effect. If the p-value for the interaction effect is less than the p-values for the main effects, we can conclude that there is an interaction effect.\n",
    "\n",
    "Note that the interpretation of the results may also depend on the specific research question and hypotheses being tested.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ec4c2",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2031a32",
   "metadata": {},
   "source": [
    "In this example, we assume that the control and experimental group test scores are stored in two separate numpy arrays called control_scores and experimental_scores. We then use the ttest_ind() function from the scipy.stats module to conduct a two-sample t-test to determine if there are any significant differences in test scores between the two groups. The ttest_ind() function returns the t-statistic and p-value for the test.\n",
    "\n",
    "If the p-value is less than 0.05, we can conclude that there is a statistically significant difference in test scores between the two groups. In this case, we may want to conduct a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "\n",
    "To conduct a post-hoc test in Python, we can use the ttest_posthoc() function from the scipy.stats module. The ttest_posthoc() function returns a matrix of p-values for all pairwise comparisons between the groups. We can then interpret these results using a significance level of 0.05. If a p-value is less than 0.05, we can conclude that there is a significant difference between the two groups being compared.\n",
    "\n",
    "Note that there are several types of post-hoc tests available, and the choice of test may depend on the specific research question and hypotheses being tested. In our example code snippet, we use the ttest_posthoc() function with the default method='hs' parameter, which performs a Holm-Sidak post-hoc test.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f932a",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of threeretail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each storeon those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16975918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated measures ANOVA results:\n",
      "              sum_sq    df          F        PR(>F)\n",
      "store     162.222222   2.0  27.141026  6.923144e-10\n",
      "Residual  260.000000  87.0        NaN           NaN\n",
      "Post-hoc results:\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------\n",
      "     A      B   0.3333 0.7364 -0.731 1.3977  False\n",
      "     A      C      3.0    0.0 1.9357 4.0643   True\n",
      "     B      C   2.6667    0.0 1.6023  3.731   True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create sample data\n",
    "sales_data = pd.DataFrame({\n",
    "    'store': ['A', 'B', 'C'] * 30,\n",
    "    'sales': [10, 12, 15, 13, 14, 16, 11, 9, 12] * 10\n",
    "})\n",
    "\n",
    "# conduct repeated measures ANOVA\n",
    "model = ols('sales ~ store', data=sales_data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print results\n",
    "print('Repeated measures ANOVA results:')\n",
    "print(anova_table)\n",
    "\n",
    "# conduct post-hoc test\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "posthoc_results = pairwise_tukeyhsd(sales_data['sales'], sales_data['store'])\n",
    "\n",
    "# print post-hoc results\n",
    "print('Post-hoc results:')\n",
    "print(posthoc_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105f719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
